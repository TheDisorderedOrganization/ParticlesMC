<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Molecular Monte Carlo · ParticlesMC</title><meta name="title" content="Molecular Monte Carlo · ParticlesMC"/><meta property="og:title" content="Molecular Monte Carlo · ParticlesMC"/><meta property="twitter:title" content="Molecular Monte Carlo · ParticlesMC"/><meta name="description" content="Documentation for ParticlesMC."/><meta property="og:description" content="Documentation for ParticlesMC."/><meta property="twitter:description" content="Documentation for ParticlesMC."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="ParticlesMC logo"/></a><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Manual</span><ul><li class="is-active"><a class="tocitem" href>Molecular Monte Carlo</a><ul class="internal"><li><a class="tocitem" href="#Birth-of-Molecular-MCMC"><span>Birth of Molecular MCMC</span></a></li><li><a class="tocitem" href="#Monte-Carlo-Moves:-Actions-and-Policies"><span>Monte Carlo Moves: Actions and Policies</span></a></li><li><a class="tocitem" href="#Choosing-the-right-parameters"><span>Choosing the right parameters</span></a></li></ul></li><li><a class="tocitem" href="../architecture/">Package Architecture</a></li><li><a class="tocitem" href="../simulations/">Running simulations</a></li></ul></li><li><a class="tocitem" href="../../api/">API</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Manual</a></li><li class="is-active"><a href>Molecular Monte Carlo</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Molecular Monte Carlo</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/TheDisorderedOrganization/ParticlesMC" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/TheDisorderedOrganization/ParticlesMC/blob/main/docs/src/man/particlesmc.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Molecular-Monte-Carlo"><a class="docs-heading-anchor" href="#Molecular-Monte-Carlo">Molecular Monte Carlo</a><a id="Molecular-Monte-Carlo-1"></a><a class="docs-heading-anchor-permalink" href="#Molecular-Monte-Carlo" title="Permalink"></a></h1><p>To see an introduction to Markov Chain Monte Carlo, please read <em>Arianna</em>&#39;s <a href="https://thedisorderedorganization.github.io/Arianna.jl/stable/man/montecarlo/">documentation</a>.</p><h2 id="Birth-of-Molecular-MCMC"><a class="docs-heading-anchor" href="#Birth-of-Molecular-MCMC">Birth of Molecular MCMC</a><a id="Birth-of-Molecular-MCMC-1"></a><a class="docs-heading-anchor-permalink" href="#Birth-of-Molecular-MCMC" title="Permalink"></a></h2><p>The pioneering application of the Metropolis algorithm by Metropolis <em>et al.</em><sup class="footnote-reference"><a id="citeref-1" href="#footnote-1" class="footnote-ref">[1]</a><span class="footnote-preview" id="fn-1"></span></sup> focused on sampling the equilibrium distribution of a system consisting of <span>$N = 224$</span> hard disks. A microstate of the system is fully characterized by the set of particle positions in space, <span>$x = {\{ \mathbf{r}_j \}}_{j=1}^N$</span>  where <span>$\mathbf{r}_j$</span> denotes the position of particle <span>$j$</span>. Consequently, the configuration space is the <span>$2N$</span>-dimensional space of particle coordinates.</p><p>The target distribution <span>$P$</span> corresponds to the Boltzmann distribution, whose probability density is given by:</p><p class="math-container">\[p_B(x) \propto \exp\left[-\frac{U(x)}{T}\right],\]</p><p>where <span>$U(x)$</span> is the potential energy associated with configuration <span>$x$</span>, and <span>$T$</span> denotes the temperature of the system.</p><p>The proposed Monte Carlo move in their study consists of sequentially displacing the disks by a random vector with uniformly distributed magnitude and direction. Each particle displacement from <span>$x$</span> to <span>$x&#39;$</span> is accepted or rejected according to the Metropolis acceptance probability,</p><p class="math-container">\[\alpha(x,x&#39;) = \min \left\{ 1, \exp\left[-\frac{\Delta U}{T}\right] \right\},\]</p><p>where <span>$\Delta U = U(x&#39;) - U(x)$</span> represents the change in potential energy resulting from the proposed displacement. In this hard disk case, the difference is either infinity or <span>$0$</span> depending if the displaced disk overlaps with another disk or not. We directly see that detailed balance is not respected as particles are not selected at random but sequentially,  meaning that <span>$q(x, x&#39;) \neq q(x&#39;, x)$</span>.</p><p>That is why this displacement move has later been modified in two steps, such that it respects detailed balance: </p><ol><li>Select a particle uniformly at random from the system.</li><li>Displace the chosen particle by a random vector with uniformly distributed magnitude and direction.</li></ol><p>This simple move type subsequently became the standard Monte Carlo move in liquid-state physics and remains widespread today.  Notably, the original simulation determined numerically the equation of state for this system.</p><p>The simulation was performed on the Los Alamos MANIAC I computer (Mathematical Analyzer Numerical Integrator and Automatic Computer Model I).  The researchers conducted a burn-in (equilibration) phase of 16 sweeps (where one sweep consists of <span>$N$</span> attempted moves), followed by a production run of 48 to 64 sweeps.  Each sweep required approximately 3 minutes of computation time, resulting in a total runtime of about 4 hours. By contrast, the same calculation would take approximately  10 milliseconds on a modern laptop, representing a performance improvement of roughly six orders of magnitude.</p><h1 align="center">
  <img src="https://raw.githubusercontent.com/TheDisorderedOrganization/ParticlesMC/main/docs/src/assets/maniac.jpg" width="500"/>
</h1>

<p align="center"> The MANIAC I computer at Los Alamos National Laboratory, where Arianna Rosenbluth implemented the first MCMC algorithm. 
This machine represented the cutting edge of computational capability in the 1950s. Image taken from Ref.~\cite{maniac}.</p><h2 id="Monte-Carlo-Moves:-Actions-and-Policies"><a class="docs-heading-anchor" href="#Monte-Carlo-Moves:-Actions-and-Policies">Monte Carlo Moves: Actions and Policies</a><a id="Monte-Carlo-Moves:-Actions-and-Policies-1"></a><a class="docs-heading-anchor-permalink" href="#Monte-Carlo-Moves:-Actions-and-Policies" title="Permalink"></a></h2><p>The transition from state <span>$x$</span> to state <span>$x&#39;$</span> in the MH algorithm is commonly referred to as a <em>Monte Carlo move</em>. Monte Carlo moves can be conceptually decomposed into two components<sup class="footnote-reference"><a id="citeref-2" href="#footnote-2" class="footnote-ref">[2]</a><span class="footnote-preview" id="fn-2"></span></sup>:</p><ul><li><strong>Actions:</strong> The type of modification applied to the system (e.g., particle displacement, rotation, swap, flip).</li><li><strong>Policies:</strong> The probabilistic rules governing how the action parameters are sampled (e.g., the distribution of displacement magnitudes and directions). Policies can be symmetric or non-symmetric. If a policy is symmetric, then the Metropolis algorithm is employed, else the Metropolis-Hastings algorithm is employed.</li></ul><p>To illustrate this distinction, consider the move employed in the original Metropolis simulation. The <em>action</em> is the translation of a randomly selected particle.  To satisfy the detailed balance condition with the symmetric Metropolis acceptance rule, the translation&#39;s direction and magnitude can be sampled from a symmetric distribution, for example uniform, Gaussian, exponential, etc. The choice of this distribution constitutes the <em>policy</em>.</p><p>Transitions between successive states, <span>$x_i \to x_{i+1}$</span>, need not be governed by a single type of Monte Carlo move. In practice, it is often advantageous to define a pool of  distinct move types and to select one randomly from this pool at each step of the Markov chain. To each move type <span>$m$</span> in the pool, one assigns a selection probability  <span>$p_m$</span>, with the normalization condition <span>$\sum_{m} p_m = 1$</span>. This collection of moves, together with their associated probabilities, can be regarded as a single composite Monte Carlo move.</p><h2 id="Choosing-the-right-parameters"><a class="docs-heading-anchor" href="#Choosing-the-right-parameters">Choosing the right parameters</a><a id="Choosing-the-right-parameters-1"></a><a class="docs-heading-anchor-permalink" href="#Choosing-the-right-parameters" title="Permalink"></a></h2>
<h1 align="center">
  <img src="https://raw.githubusercontent.com/TheDisorderedOrganization/ParticlesMC/main/docs/src/assets/goodpolicy.png" width="800"/>
</h1>

<p align="center"> Markov chain state space exploration for three different displacement policies. The system is a 1D particle in a potential well $U(x)$, with the target distribution being the Boltzmann distribution. The proposed move is the following: the action is the displacement of the particle and the policy is the distribution of the displacement magnitude and direction. Here, the policy is an uniform law $\sim \mathcal{U}(-u,u)$ with $u>0$. Each dot represents a state in the Markov chain, constructed from bottom to top. The horizontal position of a dot is the position of the particle. <b>Center:</b> When $u$ is too small, all moves are accepted but the state space is explored inefficiently due to small step sizes. <b>Right:</b> When $u$ is too large, nearly all moves are rejected, again leading to poor exploration. <b>Left:</b> An optimal choice of $u$ balances acceptance rate and step size, achieving efficient state space sampling. This illustrates the importance of tuning the proposal distribution.</p><p>A MCMC simulation consists of two phases: a <em>burn-in</em> phase and an <em>equilibrium</em> phase<sup class="footnote-reference"><a id="citeref-3" href="#footnote-3" class="footnote-ref">[3]</a><span class="footnote-preview" id="fn-3"></span></sup>. During burn-in, initial samples are discarded because the chain has not yet reached its stationary distribution. Starting from an arbitrary initial state, early samples may overweight  low-probability regions of the state space. The burn-in period must be long enough to allow the chain to converge to the target distribution before collecting samples for analysis.</p><p>Once the chain reaches equilibrium, samples are collected to estimate properties of the system. The simulation must run long enough to  adequately explore the state space <span>$\mathcal{X}$</span>. However, successive samples are typically correlated, reducing the effective sample size. To assess sampling quality, one should examine autocorrelation functions and apply convergence diagnostics to verify that the chain has sufficiently explored <span>$\mathcal{X}$</span><sup class="footnote-reference"><a id="citeref-4" href="#footnote-4" class="footnote-ref">[4]</a><span class="footnote-preview" id="fn-4"></span></sup>.</p><p>The choice of actions and policies is critical for efficient sampling. As shown in the above Figure, a poorly chosen policy leads to  inefficient exploration of the state space. Finding optimal actions and policies are essential for effective MCMC sampling.</p><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-1"><a class="tag is-link" href="#citeref-1">1</a><em>Equation of State Calculations by Fast Computing Machines</em>, Metropolis, Nicholas and Rosenbluth, Arianna W. and Rosenbluth, Marshall N. and Teller, Augusta H. and Teller, Edward, 1953</li><li class="footnote" id="footnote-2"><a class="tag is-link" href="#citeref-2">2</a><em>Reinforcement learning: An introduction</em>, Sutton, Richard S and Barto, Andrew G and others, 1998</li><li class="footnote" id="footnote-3"><a class="tag is-link" href="#citeref-3">3</a><em>Monte Carlo methods</em>, Guiselin, Benjamin, 2024</li><li class="footnote" id="footnote-4"><a class="tag is-link" href="#citeref-4">4</a><em>Convergence diagnostics for markov chain monte carlo</em>, Roy, Vivekananda, 2020</li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../">« Home</a><a class="docs-footer-nextpage" href="../architecture/">Package Architecture »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.1 on <span class="colophon-date" title="Wednesday 21 January 2026 09:31">Wednesday 21 January 2026</span>. Using Julia version 1.12.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
